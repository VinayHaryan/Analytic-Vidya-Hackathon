{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"/Users/lalitsachan/Dropbox/DLV1/Download Data/Subscribers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 51)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V42</th>\n",
       "      <th>V43</th>\n",
       "      <th>V44</th>\n",
       "      <th>V45</th>\n",
       "      <th>V46</th>\n",
       "      <th>V47</th>\n",
       "      <th>V48</th>\n",
       "      <th>V49</th>\n",
       "      <th>V50</th>\n",
       "      <th>Subscribers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.211875</td>\n",
       "      <td>743952.92</td>\n",
       "      <td>743952.92</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>743952.92</td>\n",
       "      <td>200000.000</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>-0.069396</td>\n",
       "      <td>943952.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.034232e+06</td>\n",
       "      <td>1966.57</td>\n",
       "      <td>1990.82</td>\n",
       "      <td>1752.89</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>1826.046667</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2557.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.241488</td>\n",
       "      <td>11295310.87</td>\n",
       "      <td>8034290.99</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>8034290.99</td>\n",
       "      <td>18000.000</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>0.167411</td>\n",
       "      <td>7508345.76</td>\n",
       "      <td>1160925.13</td>\n",
       "      <td>...</td>\n",
       "      <td>5.665658e+07</td>\n",
       "      <td>49957.65</td>\n",
       "      <td>11104.54</td>\n",
       "      <td>17711.99</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26467.683330</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12807.07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.459032</td>\n",
       "      <td>20363.68</td>\n",
       "      <td>317922.94</td>\n",
       "      <td>1650000.0</td>\n",
       "      <td>317922.94</td>\n",
       "      <td>1650000.000</td>\n",
       "      <td>1650000.0</td>\n",
       "      <td>46.068404</td>\n",
       "      <td>1655168.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.654720e+04</td>\n",
       "      <td>453.96</td>\n",
       "      <td>9.64</td>\n",
       "      <td>58.83</td>\n",
       "      <td>45072.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>315.506667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>856120.91</td>\n",
       "      <td>856120.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>856120.91</td>\n",
       "      <td>45554.885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>856120.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.506973e+05</td>\n",
       "      <td>2045.09</td>\n",
       "      <td>2045.09</td>\n",
       "      <td>2011.19</td>\n",
       "      <td>45072.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2045.090000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2029.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.270783</td>\n",
       "      <td>194485.64</td>\n",
       "      <td>412330.33</td>\n",
       "      <td>835000.0</td>\n",
       "      <td>412330.33</td>\n",
       "      <td>835000.000</td>\n",
       "      <td>835000.0</td>\n",
       "      <td>-0.272225</td>\n",
       "      <td>2241.64</td>\n",
       "      <td>78625.00</td>\n",
       "      <td>...</td>\n",
       "      <td>5.572559e+04</td>\n",
       "      <td>70.01</td>\n",
       "      <td>100.60</td>\n",
       "      <td>89.59</td>\n",
       "      <td>31080.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.580000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1           V2          V3         V4          V5           V6  \\\n",
       "0 -0.211875    743952.92   743952.92   200000.0   743952.92   200000.000   \n",
       "1  0.241488  11295310.87  8034290.99    32000.0  8034290.99    18000.000   \n",
       "2  0.459032     20363.68   317922.94  1650000.0   317922.94  1650000.000   \n",
       "3  0.000000    856120.91   856120.91        0.0   856120.91    45554.885   \n",
       "4  8.270783    194485.64   412330.33   835000.0   412330.33   835000.000   \n",
       "\n",
       "          V7         V8          V9         V10  ...           V42       V43  \\\n",
       "0   200000.0  -0.069396   943952.92        0.00  ...  1.034232e+06   1966.57   \n",
       "1    14000.0   0.167411  7508345.76  1160925.13  ...  5.665658e+07  49957.65   \n",
       "2  1650000.0  46.068404  1655168.31        0.00  ...  2.654720e+04    453.96   \n",
       "3        0.0   0.000000   856120.91        0.00  ...  8.506973e+05   2045.09   \n",
       "4   835000.0  -0.272225     2241.64    78625.00  ...  5.572559e+04     70.01   \n",
       "\n",
       "        V44       V45       V46    V47           V48   V49       V50  \\\n",
       "0   1990.82   1752.89  100000.0  147.0   1826.046667  28.0   2557.22   \n",
       "1  11104.54  17711.99   38000.0   19.0  26467.683330  19.0  12807.07   \n",
       "2      9.64     58.83   45072.0    0.0    315.506667   0.0     32.12   \n",
       "3   2045.09   2011.19   45072.0   30.0   2045.090000  19.0   2029.79   \n",
       "4    100.60     89.59   31080.0    0.0    294.580000   0.0     26.95   \n",
       "\n",
       "   Subscribers  \n",
       "0            0  \n",
       "1            0  \n",
       "2            1  \n",
       "3            0  \n",
       "4            0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.get_dummies(data['Subscribers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299970</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299971</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299972</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299973</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299974</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299975</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299976</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299977</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299978</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299979</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299980</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299981</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299982</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299983</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299984</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299985</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299986</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299987</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299988</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299989</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299990</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299991</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299992</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299993</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299994</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  1\n",
       "0       1  0\n",
       "1       1  0\n",
       "2       0  1\n",
       "3       1  0\n",
       "4       1  0\n",
       "5       1  0\n",
       "6       1  0\n",
       "7       1  0\n",
       "8       0  1\n",
       "9       1  0\n",
       "10      0  1\n",
       "11      1  0\n",
       "12      0  1\n",
       "13      0  1\n",
       "14      1  0\n",
       "15      1  0\n",
       "16      1  0\n",
       "17      1  0\n",
       "18      1  0\n",
       "19      0  1\n",
       "20      1  0\n",
       "21      1  0\n",
       "22      1  0\n",
       "23      1  0\n",
       "24      0  1\n",
       "25      1  0\n",
       "26      1  0\n",
       "27      1  0\n",
       "28      1  0\n",
       "29      1  0\n",
       "...    .. ..\n",
       "299970  1  0\n",
       "299971  0  1\n",
       "299972  1  0\n",
       "299973  1  0\n",
       "299974  1  0\n",
       "299975  0  1\n",
       "299976  1  0\n",
       "299977  1  0\n",
       "299978  1  0\n",
       "299979  1  0\n",
       "299980  1  0\n",
       "299981  1  0\n",
       "299982  0  1\n",
       "299983  1  0\n",
       "299984  1  0\n",
       "299985  1  0\n",
       "299986  0  1\n",
       "299987  1  0\n",
       "299988  0  1\n",
       "299989  1  0\n",
       "299990  1  0\n",
       "299991  1  0\n",
       "299992  0  1\n",
       "299993  1  0\n",
       "299994  1  0\n",
       "299995  1  0\n",
       "299996  1  0\n",
       "299997  1  0\n",
       "299998  1  0\n",
       "299999  0  1\n",
       "\n",
       "[300000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(['Subscribers'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,\n",
    "                                               random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.reset_index(drop=True,inplace=True)\n",
    "y_train.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "st=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=pd.DataFrame(st.transform(x_train))\n",
    "x_test=pd.DataFrame(st.transform(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240000, 50)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.random.normal(shape=(50, 2), dtype=tf.float64))\n",
    "biases  = tf.Variable(tf.random.normal(shape=(2,), dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(x):\n",
    "    lr = tf.add(tf.matmul(x, weights), biases)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def cross_entropy(y_true, y_pred):\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.cast(tf.argmax(y_true, axis=1), dtype=tf.int32)\n",
    "    preds = tf.cast(tf.argmax(y_pred, axis=1), dtype=tf.int32)\n",
    "    preds = tf.equal(y_true, preds)\n",
    "    return tf.reduce_mean(tf.cast(preds, dtype=tf.float32))\n",
    "\n",
    "def roc_auc(y_true,x):\n",
    "    y_true = tf.cast(tf.argmax(y_true, axis=1), dtype=tf.int32).numpy()\n",
    "    y_pred=tf.nn.softmax(logistic_regression(x))[:,1]\n",
    "    return(roc_auc_score(y_true,y_pred))\n",
    "\n",
    "def grad(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = logistic_regression(x)\n",
    "        loss_val = cross_entropy(y, y_pred)\n",
    "    return tape.gradient(loss_val, [weights, biases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=tf.cast(tf.argmax(y_test.values,axis=1),dtype=tf.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=tf.cast(tf.argmax(logistic_regression(x_test.values),axis=1),dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=87, shape=(), dtype=float32, numpy=0.60125>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(tf.cast(tf.equal(y_true,preds),dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60176665 0.4332304912887725\n",
      "0.62953335 0.4428156397485393\n",
      "0.65725 0.4517859360803791\n",
      "0.68685 0.4635383439973049\n",
      "0.7139 0.4763607804788827\n",
      "0.7366167 0.4888217520840601\n",
      "0.7522 0.5021394768598669\n",
      "0.7646667 0.5141496260028668\n",
      "0.7755167 0.5265219570555445\n",
      "0.7859167 0.5381208495153939\n",
      "0.7934333 0.5481984630729698\n",
      "0.80083334 0.55723717160843\n",
      "0.8063167 0.5672012281955553\n",
      "0.81056666 0.5748753950511449\n",
      "0.8147333 0.5815022586079338\n",
      "0.81745 0.5871911254115898\n",
      "0.8185833 0.5914233254355993\n",
      "0.8193333 0.5947994228941059\n",
      "0.82015 0.5987885603596542\n",
      "0.82021666 0.6006240033872418\n",
      "0.82033336 0.6040015827796474\n",
      "0.8202 0.6078164000773412\n",
      "0.82035 0.6099088125921891\n",
      "0.8203833 0.6127322786319574\n",
      "0.8203167 0.6149463621205301\n",
      "0.8204 0.6168280567251707\n",
      "0.82051665 0.6183513831775115\n",
      "0.8204167 0.6199565647420991\n",
      "0.8204167 0.6205453262368167\n",
      "0.8204 0.6214830699768445\n",
      "0.8204833 0.6231883851409479\n",
      "0.8205 0.6239022914109361\n",
      "0.82046664 0.6247782892076784\n",
      "0.82055 0.6251827057450402\n",
      "0.8208 0.625819285739668\n",
      "0.82063335 0.6274024239038373\n",
      "0.82061666 0.6283731003766327\n",
      "0.8207 0.6287122610244334\n",
      "0.8207667 0.6296240929011292\n",
      "0.82088333 0.6304751674417282\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.01\n",
    "for epoch in range(epochs):\n",
    "    rand_ind=np.random.choice(range(x_train.shape[0]),100)\n",
    "    outputs=y_train.iloc[rand_ind,:].values\n",
    "    inputs=x_train.iloc[rand_ind,:].values\n",
    "    \n",
    "    dw,db=grad(inputs,tf.cast(outputs,'float32'))\n",
    "    \n",
    "    weights.assign_sub(learning_rate*dw)\n",
    "    biases.assign_sub(learning_rate*db)\n",
    "    \n",
    "    if epoch%50==0:\n",
    "        print(accuracy(y_test.values,logistic_regression(x_test.values)).numpy(),roc_auc(y_test.values,x_test.values))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classfier with a hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_h = tf.Variable(tf.random.truncated_normal(shape=(50, 20), dtype=tf.float64))\n",
    "biases_h  = tf.Variable(tf.random.truncated_normal(shape=(20,), dtype=tf.float64))\n",
    "\n",
    "weights_o = tf.Variable(tf.random.truncated_normal(shape=(20, 2), dtype=tf.float64))\n",
    "biases_o  = tf.Variable(tf.random.truncated_normal(shape=(2,), dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(x):\n",
    "    h_o = tf.add(tf.matmul(x, weights_h), biases_h)\n",
    "    h_o=tf.nn.relu(h_o)\n",
    "    lr=tf.add(tf.matmul(h_o, weights_o), biases_o)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def cross_entropy(y_true, y_pred):\n",
    "\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.cast(tf.argmax(y_true, axis=1), dtype=tf.int32)\n",
    "    preds = tf.cast(tf.argmax(y_pred, axis=1), dtype=tf.int32)\n",
    "    preds = tf.equal(y_true, preds)\n",
    "    return tf.reduce_mean(tf.cast(preds, dtype=tf.float32))\n",
    "\n",
    "def roc_auc(y_true,x):\n",
    "    y_true = tf.cast(tf.argmax(y_true, axis=1), dtype=tf.int32).numpy()\n",
    "    y_pred=tf.nn.softmax(logistic_regression(x))[:,1]\n",
    "    return(roc_auc_score(y_true,y_pred))\n",
    "\n",
    "def grad(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = logistic_regression(x)\n",
    "        loss_val = cross_entropy(y, y_pred)\n",
    "    return tape.gradient(loss_val, [weights_h, biases_h,weights_o, biases_o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4182 0.4940074529962804\n",
      "0.66153336 0.5420660310826384\n",
      "0.73401666 0.5602627120836926\n",
      "0.74831665 0.5743913585134424\n",
      "0.7682 0.5917408246448503\n",
      "0.78195 0.5974419171589532\n",
      "0.78575 0.6002773236588729\n",
      "0.78325 0.6040887032997496\n",
      "0.78815 0.6059641136059241\n",
      "0.79656667 0.6081882169995749\n",
      "0.7970667 0.6114793557835423\n",
      "0.80065 0.6140047352643195\n",
      "0.79695 0.614146103161715\n",
      "0.8020667 0.6174772082473847\n",
      "0.80793333 0.6216634898119808\n",
      "0.81591666 0.6244591087800753\n",
      "0.81005 0.621897225076527\n",
      "0.8107 0.6230655086916587\n",
      "0.8155 0.6255788441625196\n",
      "0.8132667 0.6272085425992675\n",
      "0.81123334 0.6270385803134986\n",
      "0.82351667 0.630996210320873\n",
      "0.8166 0.6297133908969472\n",
      "0.80728334 0.6328734952685455\n",
      "0.81336665 0.6339699759136994\n",
      "0.81631666 0.6321686105276006\n",
      "0.8168333 0.6360640471785545\n",
      "0.8193 0.6353130593470118\n",
      "0.8203 0.6375375798703758\n",
      "0.8206 0.6396559833762068\n",
      "0.8189 0.6395797941944906\n",
      "0.8214667 0.6397293591303489\n",
      "0.82315 0.6412754997450371\n",
      "0.8226167 0.6424351887296842\n",
      "0.8175833 0.6429290195121283\n",
      "0.8214333 0.644638106427573\n",
      "0.8201 0.648282341117793\n",
      "0.8181 0.6425025664125404\n",
      "0.8175833 0.6398768608859864\n",
      "0.8225333 0.6438121397743017\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.01\n",
    "for epoch in range(epochs):\n",
    "    rand_ind=np.random.choice(range(x_train.shape[0]),100)\n",
    "    outputs=y_train.iloc[rand_ind,:].values\n",
    "    inputs=x_train.iloc[rand_ind,:].values\n",
    "    \n",
    "    dw_h,db_h,dw_o,db_o=grad(inputs,tf.cast(outputs,'float32'))\n",
    "    \n",
    "    weights_h.assign_sub(learning_rate*dw_h)\n",
    "    biases_h.assign_sub(learning_rate*db_h)\n",
    "    weights_o.assign_sub(learning_rate*dw_o)\n",
    "    biases_o.assign_sub(learning_rate*db_o)\n",
    "    \n",
    "    if epoch%50==0:\n",
    "        print(accuracy(y_test.values,logistic_regression(x_test.values)).numpy(),roc_auc(y_test.values,x_test.values))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
