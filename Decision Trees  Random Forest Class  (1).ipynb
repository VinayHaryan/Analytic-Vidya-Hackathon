{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be demonstrating just the classification problems , you can build regression following a very similar process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data prep from previous module\n",
    "file=r'/Users/lalitsachan/Dropbox/0.0 Data/census_income.csv'\n",
    "\n",
    "ci_train=pd.read_csv(file)\n",
    "\n",
    "# if you have a test data, you can combine as shown in the earlier modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(ci_train['education'],ci_train['education.num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ci_train.drop(['education'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_train['Y'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ci_train['Y']=(ci_train['Y']==' >50K').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_cols=ci_train.select_dtypes(['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    freqs=ci_train[col].value_counts()\n",
    "    k=freqs.index[freqs>500][:-1]\n",
    "    for cat in k:\n",
    "        name=col+'_'+cat\n",
    "        ci_train[name]=(ci_train[col]==cat).astype(int)\n",
    "    del ci_train[col]\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train=ci_train.drop(['Y'],1)\n",
    "y_train=ci_train['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameters For Decision Trees\n",
    "\n",
    "* criterion : there are two options available , \"entropy\" and \"gini\". These are the homogeneity measures that we discussed. By default \"gini\" is used \n",
    "\n",
    "* The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. Ignored if ``max_leaf_nodes`` is not None. We'll finding optimal value for max_leaf_nodes [which is basically size of the tree] through cross validation.\n",
    "\n",
    "* min_sample_split : The minimum number of samples required to split an internal node. defaults to too, good idea is to keep it slightly higher in order to reduce overfitting of the data. recommended values is between 5 to 10\n",
    "\n",
    "* min_sample_leaf : The minimum number of samples required to be at a leaf node. This defaults to 1. If this number is higher and a split results in a leaf node having lesser number of samples than specified then that split is cancelled.\n",
    "\n",
    "* max_leaf_node : this parameter controlls size of the tree, we'll be finding optimal value of this through cross validation\n",
    "\n",
    "* class_weight : this default to None in which case each class is given equal weightage. If the goal of the problem is good classification instead of accuracy then you should set this to \"balanced\", in which case class weights are assigned inversely proportional to class frequencies in the input data.\n",
    "\n",
    "* random_state : this is used to reproduce random result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params={ 'class_weight':[None,'balanced'], \n",
    "        'criterion':['entropy','gini'],\n",
    "        'max_depth':[None,5,10,15,20,30,50,70],\n",
    "            'min_samples_leaf':[1,2,5,10,15,20], \n",
    "            'min_samples_split':[2,5,10,15,20]\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2*2*8*6*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_search=RandomizedSearchCV(clf,cv=10,\n",
    "                                 param_distributions=params,\n",
    "                                 scoring='roc_auc',\n",
    "                                 n_iter=10\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the tree model is a little tricky in python. We'll have to output our tree to a .dot file using graphviz package. From there using graphviz.Source function we can print our tree for display. Here is how :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.5f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report(random_search.cv_results_,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtree=random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dotfile = open(\"mytree.dot\", 'w')\n",
    "\n",
    "tree.export_graphviz(dtree,out_file=dotfile,\n",
    "                     feature_names=x_train.columns,\n",
    "                    class_names=[\"0\",\"1\"],\n",
    "                     proportion=True)\n",
    "dotfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open mytree.dot file in a simple text editor and copy and paste the code here to visualise your tree : http://webgraphviz.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Hyper paprameters for RandomForests\n",
    "\n",
    "* n_estimators : number of trees in the forest . defaults to 10. good starting point will be 100. Its one of the hyper parameters. We'll see how to search through mutidimensional hyper parameter space in order to find optimal combination through randomised grid search\n",
    "\n",
    "* max_features : Number of features being considered for rule selection at each split. Look at the documentation for defaults\n",
    "\n",
    "* bootstrap : boolean values, Whether bootstrap samples are used when building trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this here is the base classifier we are going to try\n",
    "# we will be supplying different parameter ranges to our randomSearchCV which in turn\n",
    "# will pass it on to this classifier\n",
    "\n",
    "# Utility function to report best scores. This simply accepts grid scores from \n",
    "# our randomSearchCV/GridSearchCV and picks and gives top few combination according to \n",
    "# their scores\n",
    "\n",
    "# RandomSearchCV/GridSearchCV accept parameters values as dictionaries.\n",
    "# In example given below we have constructed dictionary for \n",
    "#different parameter values that we want to\n",
    "# try for randomForest model\n",
    "\n",
    "param_dist = {\"n_estimators\":[100,200,300,500,700,1000],\n",
    "              \"max_features\": [5,10,20,25,30,35],\n",
    "              \"bootstrap\": [True, False],\n",
    "              'class_weight':[None,'balanced'], \n",
    "                'criterion':['entropy','gini'],\n",
    "                'max_depth':[None,5,10,15,20,30,50,70],\n",
    "                'min_samples_leaf':[1,2,5,10,15,20], \n",
    "                'min_samples_split':[2,5,10,15,20]\n",
    "                  }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "960*6*6*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run randomized search\n",
    "n_iter_search = 10\n",
    "# n_iter parameter of RandomizedSeacrhCV controls, how many \n",
    "# parameter combination will be tried; out of all possible given values\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search,scoring='roc_auc',cv=5)\n",
    "random_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=50, max_features=10, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=10,\n",
    "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=300, n_jobs=1, oob_score=False, random_state=None,\n",
    "            verbose=0, warm_start=False)\n",
    "            \n",
    "**Note: This is a result from one of the runs, you can very well get different results from a different run. Your results need not match with this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report(random_search.cv_results_,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select the best values from results above, they will vary slightly with each run\n",
    "rf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini', max_depth=50, \n",
    "                          max_features=10, max_leaf_nodes=None, min_impurity_split=1e-07, \n",
    "                          min_samples_leaf=10, min_samples_split=20, min_weight_fraction_leaf=0.0, \n",
    "                          n_estimators=300, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df=pd.DataFrame({'features':x_train.columns,'importance':rf.feature_importances_})\n",
    "\n",
    "feat_imp_df.sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Dependence Plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_name='education.num'\n",
    "\n",
    "preds=rf.predict_proba(x_train)[:,1]\n",
    "# part_dep_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_data=pd.DataFrame({'var':x_train[var_name],'response':preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.lmplot(x='var',y='response',data=var_data,fit_reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "smooth_data=sm.nonparametric.lowess(var_data['response'],var_data['var'])\n",
    "\n",
    "# smooth_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'response':smooth_data[:,1],var_name:smooth_data[:,0]})\n",
    "\n",
    "sns.lmplot(x=var_name,y='response',data=df,fit_reg=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
