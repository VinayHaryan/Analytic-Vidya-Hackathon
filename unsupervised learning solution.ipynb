{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning Exercise Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "myfile='~/Dropbox/March onwards/Python Data Science/Data/winequality-red.csv'\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "wine=pd.read_csv(myfile,sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine=wine[[\"sulphates\",\"alcohol\",\"pH\"]]\n",
    "\n",
    "wine_std=pd.DataFrame(scale(wine),columns=list(wine.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ks=np.linspace(2,15,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssw=[]\n",
    "for k in Ks:\n",
    "    kmeans=KMeans(n_clusters=int(k))\n",
    "    kmeans.fit(wine_std)\n",
    "    sil_score=silhouette_score(wine_std,kmeans.labels_)\n",
    "    print(\"for inertia:\" ,kmeans.inertia_ ,\"and silhouette score:\",sil_score,\"number of clusters are:\", int(k))\n",
    "    ssw.append(kmeans.inertia_)\n",
    "plt.plot(Ks,ssw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here selected number of cluster = 6\n",
    "k = 6\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "kmeans.fit(wine_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = kmeans.labels_\n",
    "wine_std[\"cluster\"]=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ggplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(wine_std,aes(x='sulphates',y='alcohol'))+geom_point(aes(color='cluster'),size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(wine_std,aes(x='sulphates',y='pH'))+geom_point(aes(color='cluster'),size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(wine_std,aes(x='alcohol',y='pH'))+geom_point(aes(color='cluster'),size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overlap we see here is not actually an overlap but its a 6 dimensional view in a 2D space. Meaning there are 6 clusters formed in 6D space and when you see them in 2D space its seems to be overlapped but in reality they never overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dbscan doesnt have a good measure and all the internal measures are either suited to k-means or they need labeled data . \n",
    "You need to take a subjective decision whther cluster given by dbscan make business sense or not . When you have labeled data however , dbscan can be used to make distance based similarity features and see whether labelling is consistent with the data or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myfile='~/Dropbox/March onwards/Python Data Science/Data/Wholesale customers data.csv'\n",
    "\n",
    "groc=pd.read_csv(myfile)\n",
    "\n",
    "groc=groc[[\"Milk\",\"Grocery\"]]\n",
    "\n",
    "groc_std=pd.DataFrame(scale(groc),columns=list(groc.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=np.linspace(0.5,5)\n",
    "for epsilon in r:\n",
    "    db = DBSCAN(eps=epsilon, min_samples=20, metric='euclidean').fit(groc_std)\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "    n_clust=len(set(labels))-1\n",
    "    outlier=np.round(np.count_nonzero(labels == -1)/len(labels)*100,2)\n",
    "        \n",
    "    print('Estimated number of clusters: %d', n_clust)\n",
    "    print(\"For epsilon =\", epsilon ,\", percentage of outliers is: \",outlier)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the epsilon value that gives at aleast 5% customers which are very different in terms of purchase patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=0.77, min_samples=10, metric='euclidean').fit(groc_std)\n",
    "groc_std['cluster']=[str(x) for x in db.labels_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(groc_std,aes(x='Milk',y='Grocery',color='cluster'))+geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FactorAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file='~/Dropbox/March onwards/Python Data Science/Data/cars.csv'\n",
    "cars=pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_cars=cars.drop(['Name'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_cars=pd.DataFrame(scale(X_cars),columns=X_cars.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fa=FactorAnalysis(n_components=4,max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa.fit(X_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvar=fa.noise_variance_\n",
    "plt.plot(nvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*zip(X_cars.columns,nvar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a.\n",
    "\n",
    "We will remove the variables one by one for which noice variance is higher than 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cars=X_cars.drop(['Width'],1)\n",
    "\n",
    "fa=FactorAnalysis(n_components=4,max_iter=1000)\n",
    "\n",
    "fit=fa.fit(X_cars)\n",
    "nvar=fa.noise_variance_\n",
    "print(*zip(X_cars.columns,nvar))\n",
    "plt.plot(nvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cars=X_cars.drop(['Length'],1)\n",
    "\n",
    "fa=FactorAnalysis(n_components=4,max_iter=1000)\n",
    "\n",
    "fit=fa.fit(X_cars)\n",
    "nvar=fa.noise_variance_\n",
    "print(*zip(X_cars.columns,nvar))\n",
    "plt.plot(nvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cars=X_cars.drop(['Wheelbase'],1)\n",
    "\n",
    "fa=FactorAnalysis(n_components=4,max_iter=1000)\n",
    "\n",
    "fit=fa.fit(X_cars)\n",
    "nvar=fa.noise_variance_\n",
    "print(*zip(X_cars.columns,nvar))\n",
    "plt.plot(nvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cars=X_cars.drop(['Horsepower'],1)\n",
    "\n",
    "fa=FactorAnalysis(n_components=4,max_iter=1000)\n",
    "\n",
    "fit=fa.fit(X_cars)\n",
    "nvar=fa.noise_variance_\n",
    "print(*zip(X_cars.columns,nvar))\n",
    "plt.plot(nvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings=fa.components_\n",
    "loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*zip(X_cars.columns,loadings[0,]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loadings for price variables [Retail & Dealer ] is pretty higher , they are the domninant contributors to these factors. Rest of the variables except mileage ones also contribute positively to this. We can consider this factor to be vehicle's percieved value. Higher mileage indicates towards not so high value vehicle accroding to this value indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*zip(X_cars.columns,loadings[1,]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that more weightage is given to Weight,Engine and Cylinders and the relation is inverse in nature\n",
    "which tells all these variables tends to lower the mileage of the car. We can label this factor as fuel efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*zip(X_cars.columns,loadings[2,]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that all variables are given the positive weights so we can label this factor as specs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*zip(X_cars.columns,loadings[3,]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that more weightage is given CityMPG, Weight and Cylinder. We can label this factor as torque, which is decreases with increase in Cylinders, and increases with increase in mileage and weight."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
